{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHAT THE HELL IS THIS ??? LINEAR ALGEBRA COURSE ????????????\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# input = np.array([\n",
    "# [0,0],\n",
    "# [0,1],\n",
    "# [1,0],\n",
    "# [1,1]\n",
    "# ])\n",
    "\n",
    "input = np.array([\n",
    "[0,0],\n",
    "[0,1],\n",
    "[1,0],\n",
    "[1,1]\n",
    "])\n",
    "\n",
    "output = np.array([\n",
    "[0],\n",
    "[1],\n",
    "[1],\n",
    "[0]\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta  =  0.024879284142895128\n",
      "Weights Before = [[-0.55654189  0.97148866  0.74742739]]\n",
      "Weights After = [-0.55481724  0.97270238  0.74947059]\n",
      "\n",
      "\n",
      "\n",
      "Weights Before = [[-0.52720972  0.90801124  1.37965819]\n",
      " [-0.17163992 -1.13252041 -0.76711495]]\n",
      "\n",
      "\n",
      "\n",
      " [[-0.0131166   0.02259067  0.03432491]\n",
      " [-0.00427028 -0.0281763  -0.01908527]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [[8.60226022e-05 2.55169176e-04 5.89099657e-04]\n",
      " [9.11763840e-06 3.96951857e-04 1.82123783e-04]] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " [0. 0. 0.] \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (3,) doesn't match the broadcast shape (2,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 136\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[39mreturn\u001b[39;00m allOutputs\n\u001b[0;32m    134\u001b[0m ann \u001b[39m=\u001b[39m NeuralNetwork(hiddenLayers\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,noNodes\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,binaryInput\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m,binaryOutput\u001b[39m=\u001b[39moutput)\n\u001b[1;32m--> 136\u001b[0m ann\u001b[39m.\u001b[39;49mtrain(\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    137\u001b[0m \u001b[39mprint\u001b[39m(ann\u001b[39m.\u001b[39mweights)\n",
      "Cell \u001b[1;32mIn[109], line 84\u001b[0m, in \u001b[0;36mNeuralNetwork.train\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward() \u001b[39m# Forward Feed\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m i,each \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mff):\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__backpropagation(each,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbinaryOutput[i],\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbinaryInput[i])\n",
      "Cell \u001b[1;32mIn[109], line 64\u001b[0m, in \u001b[0;36mNeuralNetwork.__backpropagation\u001b[1;34m(self, ff, output, input)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,np\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39masarray(\u001b[39minput\u001b[39m),delta)\u001b[39m.\u001b[39mT,\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m \u001b[39m# This will compute the weight and bias for the first layer\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m] \u001b[39m+\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearningRate \u001b[39m*\u001b[39;49m (np\u001b[39m.\u001b[39;49mdot(delta,\u001b[39minput\u001b[39;49m[\u001b[39m0\u001b[39;49m]))\n\u001b[0;32m     65\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearningRate \u001b[39m*\u001b[39m (np\u001b[39m.\u001b[39mdot(delta,\u001b[39minput\u001b[39m[\u001b[39m1\u001b[39m]))\n\u001b[0;32m     67\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWeights After = \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[\u001b[39m0\u001b[39m]))\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (3,) doesn't match the broadcast shape (2,3)"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self,inputSize = 2,outputSize = 1, hiddenLayers=None, noNodes = None, binaryInput = None, binaryOutput = None):\n",
    "        if (inputSize or outputSize or hiddenLayers or noNodes or binaryInput or binaryOutput ) is None:\n",
    "            raise Exception(\"Please provide all the args inputSize,outputSize, hiddenLayers, noNodes, binaryInput, binaryOutput\")\n",
    "        \n",
    "        if hiddenLayers < 1:\n",
    "            raise Exception(\"Hidden Layers should be greater than equal to 1\")\n",
    "        \n",
    "        self.inputSize = inputSize\n",
    "        self.outputSize = outputSize\n",
    "        self.hiddenLayers = hiddenLayers\n",
    "        self.noNodes = noNodes\n",
    "        self.binaryInput = binaryInput\n",
    "        self.binaryOutput = binaryOutput\n",
    "\n",
    "\n",
    "        # Initliaze weights and biases and layers and learning rate\n",
    "        self.ff = []\n",
    "        self.learningRate = 0.1\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.__initializeWeightsAndBiases()\n",
    "\n",
    "\n",
    "    def __backpropagation(self,ff,output,input):\n",
    "        # Backpropagation\n",
    "        # Output Layer to Hidden Layer\n",
    "        # This will compute the error for the last layer for all outputs\n",
    "        error =  (output - ff[-1]) \n",
    "        delta = np.dot((np.square(error)),0.5) # Delta = 1/2 * Error^2\n",
    "        delta = delta[-1][-1]\n",
    "        print(\"Delta  = \",delta)\n",
    "\n",
    "        # This will compute the weight and bias for the last layer\n",
    "        print(\"Weights Before = {}\".format(np.asarray(self.weights[-1])))\n",
    "        #print(\"FF = {}\".format(ff[-2]))\n",
    "        self.weights[-1] += self.learningRate * (np.dot(np.asarray(ff[-2]).T,delta).T)\n",
    "        self.biases[-1] += self.learningRate * delta\n",
    "        print(\"Weights After = {}\\n\\n\\n\".format(self.weights[-1][-1]))\n",
    "\n",
    "        # Hidden Layer to Hidden Layer\n",
    "        for i in range(self.hiddenLayers-1,0,-1):\n",
    "            # This will compute the error for the hidden layer\n",
    "            error = np.dot(delta,self.weights[i+1].T)\n",
    "            # This will compute the delta for the hidden layer\n",
    "            delta = error * self.ff[i] * (1 - self.ff[i])\n",
    "            # This will compute the weight and bias for the hidden layer\n",
    "            self.weights[i] += self.learningRate * np.dot(self.ff[i-1].T,delta)\n",
    "            self.biases[i] += self.learningRate * delta\n",
    "\n",
    "\n",
    "        print(\"Weights Before = {}\".format(np.asarray(self.weights[0])))\n",
    "        #print(self.ff[0])\n",
    "        # Hidden Layer to Input Layer\n",
    "        # This will compute the error for the first layer\n",
    "        error = np.dot(delta,self.weights[0].T).T\n",
    "        print(\"\\n\\n\\n\",error,\"\\n\\n\\n\")\n",
    "        # This will compute the delta for the first layer\n",
    "        delta = np.dot((np.square(error)),0.5) # Delta = 1/2 * Error^2\n",
    "        print(\"\\n\\n\\n\",delta,\"\\n\\n\\n\")\n",
    "\n",
    "        print(\"\\n\\n\\n\",np.dot(np.asarray(input),delta).T,\"\\n\\n\\n\")\n",
    "        # This will compute the weight and bias for the first layer\n",
    "        self.weights[0][0] += self.learningRate * (np.dot(delta,input[0]))\n",
    "        self.weights[0][1] += self.learningRate * (np.dot(delta,input[1]))\n",
    "\n",
    "        print(\"Weights After = {}\\n\\n\\n\".format(self.weights[0]))\n",
    "\n",
    "        #self.biases[0] = self.biases[0].T\n",
    "        self.biases[0] += self.learningRate * delta\n",
    "\n",
    "        # self.weights[0] += self.learningRate * np.dot(self.binaryInput.T,delta)\n",
    "        # self.biases[0] += self.learningRate * delta\n",
    "\n",
    "    def train(self,epochs = 100):\n",
    "        # print(\"Before Training\")\n",
    "        # for i,each in enumerate(self.weights):\n",
    "        #     print(\"Weights = {}  |  Target = {} | Input = {}\".format(each,output[i],input[i]))\n",
    "\n",
    "        for i in range(epochs):\n",
    "            self.ff = [] # Reset the feed forward list\n",
    "            self.forward() # Forward Feed\n",
    "            for i,each in enumerate(self.ff):\n",
    "                self.__backpropagation(each,self.binaryOutput[i],self.binaryInput[i]) # Back Propagation\n",
    "            \n",
    "\n",
    "        # print(\"After Training\")\n",
    "        # for i,each in enumerate(self.weights):\n",
    "        #     print(\"Weights = {}  |  Target = {} | Input = {}\".format(each,output[i],input[i]))\n",
    "\n",
    "    def forward(self):\n",
    "        for each in self.binaryInput:\n",
    "            self.ff.append(self.__computeOutput(each))\n",
    "        return self.ff\n",
    "\n",
    "\n",
    "    def __initializeWeightsAndBiases(self):\n",
    "        # Input Layer to Hidden Layer\n",
    "        self.weights.append(np.random.randn(self.inputSize,self.noNodes))\n",
    "        self.biases.append(np.random.randn(1,self.noNodes))\n",
    "\n",
    "        # Hidden Layer to Hidden Layer\n",
    "        for i in range(1,self.hiddenLayers):\n",
    "            self.weights.append(np.random.randn(self.noNodes,self.noNodes))\n",
    "            self.biases.append(np.random.randn(1,self.noNodes)) # Bias for every hidden layer\n",
    "\n",
    "        # Hidden Layer to Output Layer\n",
    "        self.weights.append(np.random.randn(self.outputSize,self.noNodes))\n",
    "        self.biases.append(np.random.randn(self.outputSize,1)) # Bias for the output layer\n",
    "\n",
    "\n",
    "    def __sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-copy.deepcopy(x)))\n",
    "    \n",
    "    # Forward Propagation\n",
    "    def __computeOutput(self,input):\n",
    "        output = copy.deepcopy(input)\n",
    "        allOutputs = []\n",
    "        #print(output,\"\\n\")\n",
    "        # This will compute the output to the last layer\n",
    "        for i in range(self.hiddenLayers +1):\n",
    "            if i == 0:\n",
    "                output = self.__sigmoid(np.dot(output,self.weights[i]) + self.biases[i])\n",
    "            else:\n",
    "                output = self.__sigmoid(np.dot(output,np.transpose(self.weights[i])) + self.biases[i])\n",
    "            allOutputs.append(output)\n",
    "\n",
    "            #print(\"Weight  = \",self.weights[i],\"Output = \",output,\"\\n\")\n",
    "\n",
    "        return allOutputs\n",
    "\n",
    "\n",
    "\n",
    "ann = NeuralNetwork(hiddenLayers=1,noNodes=3,binaryInput=input,binaryOutput=output)\n",
    "\n",
    "ann.train(1)\n",
    "print(ann.weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
