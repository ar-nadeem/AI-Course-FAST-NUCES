{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # OpenCV for Webcam\n",
    "import numpy as np # For Image processing as array\n",
    "import torch # PyTorch for Deep Learning\n",
    "from matplotlib import pyplot as plt # For plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open webcam and feed it into model if set\n",
    "# Takes in model and camera number (Camera should be 0 if using laptop webcam)\n",
    "def webCam(model = None,camera = 1):\n",
    "    cap = cv2.VideoCapture(camera)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "\n",
    "            if model != None:\n",
    "                #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                result = model(frame)\n",
    "\n",
    "                cv2.imshow('YOLO', np.squeeze(result.render()))\n",
    "            else:\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                cv2.imshow('frame', gray)\n",
    "\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitpython>=3.1.30 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 5)) (3.1.31)\n",
      "Requirement already satisfied: matplotlib>=3.3 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 6)) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 7)) (1.21.6)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 8)) (4.7.0.72)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 9)) (9.3.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 10)) (5.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 12)) (2.28.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 13)) (1.10.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 14)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 15)) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 16)) (0.15.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 17)) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 26)) (1.3.5)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 27)) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from -r yolov5/requirements.txt (line 41)) (66.0.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from gitpython>=3.1.30->-r yolov5/requirements.txt (line 5)) (4.0.10)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (23.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (2.8.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (4.25.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (3.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from requests>=2.23.0->-r yolov5/requirements.txt (line 12)) (1.26.15)\n",
      "Requirement already satisfied: filelock in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (4.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from tqdm>=4.64.0->-r yolov5/requirements.txt (line 17)) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from pandas>=1.1.4->-r yolov5/requirements.txt (line 26)) (2019.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r yolov5/requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r yolov5/requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from jinja2->torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ar-na\\anaconda3\\envs\\ai\\lib\\site-packages (from sympy->torch>=1.7.0->-r yolov5/requirements.txt (line 15)) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "        1 file(s) copied.\n"
     ]
    }
   ],
   "source": [
    "# Clone yolov5 repo if not already cloned\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "\n",
    "# Install dependencies\n",
    "%pip install -r yolov5/requirements.txt\n",
    "\n",
    "# Copy dataset.yml\n",
    "%copy dataset.yml yolov5/dataset.yml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m D:\\Git\\AI-Sentiment-Analysis-Roman-Urdu\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/yolov5s.pt, cfg=, data=yolov5/dataset.yml, hyp=yolov5\\data\\hyps\\hyp.scratch-low.yaml, epochs=1, batch_size=16, imgsz=1024, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=2, project=yolov5\\runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 \n",
      "YOLOv5  v7.0-163-g016e046 Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5  in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5\\runs\\train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5\\yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Git\\AI-Sentiment-Analysis-Roman-Urdu\\data\\labels...:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Git\\AI-Sentiment-Analysis-Roman-Urdu\\data\\labels... 1 images, 0 backgrounds, 0 corrupt:   1%|          | 1/100 [00:06<10:35,  6.42s/it]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Git\\AI-Sentiment-Analysis-Roman-Urdu\\data\\labels... 100 images, 1 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:06<00:00, 15.55it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  Cache directory D:\\Git\\AI-Sentiment-Analysis-Roman-Urdu\\data is not writeable: [WinError 183] Cannot create a file when that file already exists: 'D:\\\\Git\\\\AI-Sentiment-Analysis-Roman-Urdu\\\\data\\\\labels.cache.npy' -> 'D:\\\\Git\\\\AI-Sentiment-Analysis-Roman-Urdu\\\\data\\\\labels.cache'\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.2GB ram): 100%|██████████| 100/100 [00:00<00:00, 1135.12it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Git\\AI-Sentiment-Analysis-Roman-Urdu\\data\\labels...:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Git\\AI-Sentiment-Analysis-Roman-Urdu\\data\\labels... 1 images, 0 backgrounds, 0 corrupt:   1%|          | 1/100 [00:07<11:55,  7.22s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Git\\AI-Sentiment-Analysis-Roman-Urdu\\data\\labels... 100 images, 1 backgrounds, 0 corrupt: 100%|██████████| 100/100 [00:07<00:00, 13.80it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  Cache directory D:\\Git\\AI-Sentiment-Analysis-Roman-Urdu\\data is not writeable: [WinError 183] Cannot create a file when that file already exists: 'D:\\\\Git\\\\AI-Sentiment-Analysis-Roman-Urdu\\\\data\\\\labels.cache.npy' -> 'D:\\\\Git\\\\AI-Sentiment-Analysis-Roman-Urdu\\\\data\\\\labels.cache'\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram):  54%|█████▍    | 54/100 [00:00<00:00, 535.37it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.2GB ram): 100%|██████████| 100/100 [00:00<00:00, 596.32it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.04 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to yolov5\\runs\\train\\exp2\\labels.jpg... \n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1myolov5\\runs\\train\\exp2\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\n",
      "        0/0      7.73G     0.1255    0.06674    0.03388         40       1024:   0%|          | 0/7 [00:01<?, ?it/s]\n",
      "        0/0      7.73G     0.1255    0.06674    0.03388         40       1024:  14%|█▍        | 1/7 [00:02<00:13,  2.25s/it]\n",
      "        0/0      7.75G     0.1035    0.06603    0.02723         29       1024:  14%|█▍        | 1/7 [00:02<00:13,  2.25s/it]\n",
      "        0/0      7.75G     0.1035    0.06603    0.02723         29       1024:  29%|██▊       | 2/7 [00:02<00:05,  1.15s/it]\n",
      "        0/0      7.75G    0.09581    0.06543    0.02461         29       1024:  29%|██▊       | 2/7 [00:02<00:05,  1.15s/it]\n",
      "        0/0      7.75G    0.09581    0.06543    0.02461         29       1024:  43%|████▎     | 3/7 [00:02<00:03,  1.26it/s]\n",
      "        0/0      7.75G    0.09206    0.06486    0.02348         34       1024:  43%|████▎     | 3/7 [00:03<00:03,  1.26it/s]\n",
      "        0/0      7.75G    0.09206    0.06486    0.02348         34       1024:  57%|█████▋    | 4/7 [00:03<00:01,  1.57it/s]\n",
      "        0/0      7.75G    0.09881    0.06388    0.02458         31       1024:  57%|█████▋    | 4/7 [00:03<00:01,  1.57it/s]\n",
      "        0/0      7.75G    0.09881    0.06388    0.02458         31       1024:  71%|███████▏  | 5/7 [00:03<00:01,  1.87it/s]\n",
      "        0/0      7.75G    0.09514    0.06298    0.02366         29       1024:  71%|███████▏  | 5/7 [00:04<00:01,  1.87it/s]\n",
      "        0/0      7.75G    0.09514    0.06298    0.02366         29       1024:  86%|████████▌ | 6/7 [00:04<00:00,  2.09it/s]\n",
      "        0/0      7.75G    0.09916    0.06191    0.02474          7       1024:  86%|████████▌ | 6/7 [00:04<00:00,  2.09it/s]\n",
      "        0/0      7.75G    0.09916    0.06191    0.02474          7       1024: 100%|██████████| 7/7 [00:04<00:00,  2.61it/s]\n",
      "        0/0      7.75G    0.09916    0.06191    0.02474          7       1024: 100%|██████████| 7/7 [00:04<00:00,  1.63it/s]\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 1/4 [00:01<00:04,  1.45s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 2/4 [00:02<00:02,  1.04s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 3/4 [00:02<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 [00:03<00:00,  1.67it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 [00:03<00:00,  1.30it/s]\n",
      "                   all        100         99    0.00264      0.738    0.00246   0.000613\n",
      "\n",
      "1 epochs completed in 0.002 hours.\n",
      "Optimizer stripped from yolov5\\runs\\train\\exp2\\weights\\last.pt, 14.5MB\n",
      "Optimizer stripped from yolov5\\runs\\train\\exp2\\weights\\best.pt, 14.5MB\n",
      "\n",
      "Validating yolov5\\runs\\train\\exp2\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|██▌       | 1/4 [00:00<00:02,  1.22it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|█████     | 2/4 [00:01<00:01,  1.20it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|███████▌  | 3/4 [00:02<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 [00:02<00:00,  1.75it/s]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]\n",
      "                   all        100         99    0.00259      0.728    0.00238   0.000596\n",
      "                 happy        100         49    0.00192      0.755    0.00194   0.000519\n",
      "                   sad        100         50    0.00326        0.7    0.00282   0.000673\n",
      "Results saved to \u001b[1myolov5\\runs\\train\\exp2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "!python yolov5/train.py --img 1024 --batch 16 --epochs 100 --data yolov5/dataset.yml --weights yolov5/yolov5s.pt --cache ram --workers 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ar-na/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-5-9 Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA GeForce RTX 3070, 8192MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\ar-na\\.cache\\torch\\hub\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp14/weights/best.pt')\n",
    "#model_og = torch.hub.load('ultralytics/yolov5', 'yolov5/yolov5s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 480x640 1 neutral\n",
      "Speed: 3.0ms pre-process, 46.0ms inference, 24.3ms NMS per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "#camera = cv2.VideoCapture(1)\n",
    "import time\n",
    "img = cv2.imread('./data/test/images/16857a8c-90bc4314-ef0b-11ed-b50a-e0d4e80fd9a7.jpg')\n",
    "\n",
    "result = model(img)\n",
    "cv2.imshow('YOLO', np.squeeze(result.render()))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conf = 0.25\n",
    "webCam(model=model,camera = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
